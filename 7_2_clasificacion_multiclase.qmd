# Problemas y soluciones

## Clasificación multiclase

La clasificación multiclase se refiere a aquellos casos en los que los datos contienen etiquetas que pertenecen a una de las $C$ clases:

$$
y \in \{1,...,C\}
$$

Por ejemplo, se puede clasificar utilizando features extraídos de un set de imágenes de frutas. En este ejemplo las etiquetas `y` serían:

```{python}
y = ["manzana", "pera", "naranja"]
```

Cada imagen es una muestra y puede ser clasificada como **una** de las tres posibles clases. La clasificación multiclase asume que cada muestra está asociada a **una y solo una de las etiquetas**. 

En el ejemplo, una fotografía no podría ser una pera y una naranja al mismo tiempo. Si esto no se cumple estaríamos ante un ejemplo de clasificación multietiqueta, que se verá más adelante.

Existen algunos algoritmos de clasificación que se pueden extender para ser algoritmos de clasificación multiclase:

- ID3 y otros algoritmos de árboles de decisión
- Regresión logística reemplazando la función sigmoidal con la función softmax
- kNN

Hay otros algoritmos que no se pueden extender a clasificación multiclase de forma simple, o en algunos casos, son mucho más eficientes en el caso de clasificación binaria. Ante esta situación, una estrategia común es llamada **uno versus el resto (OVR)**.

### Uno versus el resto (OVR)

La idea detrás del enfoque de OVR es separar el problema de clasificación multiclase en múltiples casos de separación binaria.

En la siguiente figura podemos observar una ilustración con dos tipos de problemas de clasificación: binaria y multiclase.

![Ilustración de problemas de clasificación](figuras/multiclass/img1.png){fig-alt="Problemas clasificación" width="70%"}

Para la imagen de la derecha, un ejemplo de clasificación multiclase, podemos utilizar la estrategia de OVR, tal y como se muestra en la siguiente figura.

![Ilustración de la clasificación multiclase](figuras/multiclass/img2.png){fig-alt="Clasificación multiclase"}

### Implementación en python

**Imports:**
```{python}
import pandas as pd
import seaborn as sns

import numpy as np
from sklearn.multiclass import OneVsRestClassifier
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split

from sklearn.datasets import make_classification

import time
```

**Creando datos aleatorios para clasificación:**
```{python}
# Generando un array aleatorio de 1000 muestras, 10 features y una etiqueta de y=[0,1,2]
X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)

# Separando el array en conjuntos de prueba (25 %) y entrenamiento (75 %)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)

# Colocando en dataframes para facilidad de presentación y graficación
df_train = pd.DataFrame({"y":y_train, "x0":X_train[:,0], "x1":X_train[:,1], "x2":X_train[:,2], "x3":X_train[:,3], "x4":X_train[:,4], "x5":X_train[:,5], "x6":X_train[:,6], "x7":X_train[:,7], "x8":X_train[:,8], "x9":X_train[:,9]})

df_test = pd.DataFrame({"y":y_test, "x0":X_test[:,0], "x1":X_test[:,1], "x2":X_test[:,2], "x3":X_test[:,3], "x4":X_test[:,4], "x5":X_test[:,5], "x6":X_test[:,6], "x7":X_test[:,7], "x8":X_test[:,8], "x9":X_test[:,9]})

df_train
```

```{python}
ax = sns.scatterplot(data=df_train, x="x0", y="x1", hue="y", palette="tab10")
```

**Definiendo el modelo OVR**

```{python}
# Se define el modelo a usar dentro del OVR, en este caso SVC, puede ser logistico u otro
modelo = SVC()
# Entrenando el modelo con los datos de entrenamiento
clasificador = OneVsRestClassifier(modelo).fit(X_train, y_train)
```

**Probando el modelo OVR `clasificador`**

```{python}
# Probando el modelo con los datos de prueba
prediccion = clasificador.predict(X_test)

# Colocando los datos predichos en un dataframe
df_pred = pd.DataFrame({"y":prediccion, "x0":X_test[:,0], "x1":X_test[:,1], "x2":X_test[:,2], "x3":X_test[:,3], "x4":X_test[:,4], "x5":X_test[:,5], "x6":X_test[:,6], "x7":X_test[:,7], "x8":X_test[:,8], "x9":X_test[:,9]})
```

¿Cuál es el resultado del modelo `clasificador`?

Nos da un vector con las etiquetas predichas:

```{python}
print(prediccion)
```

Y con el método `score(X, y)` podemos obtener la *mean accuracy*, que es una métrica bastante exigente pues requiere que para cada muestra la etiqueta sea asignada correctamente:

```{python}
print("mean accuracy = ",clasificador.score(X_test, y_test))
```

Luego, podemos comparar la gráfica del conjunto de prueba `df_test`, utilizando por ejemplo los features $x_0$ y $x_1$:

```{python}
ax2 = sns.scatterplot(data=df_test, x="x0", y="x1", hue="y", palette="tab10")
```

Con la gráfica utilizando los mismos features $x_0$ y $x_1$ del conjunto de prueba pero esta vez con las etiquetas predichas por el modelo. Se marca una *x* roja sobre los puntos que fueron clasificados incorrectamente:

```{python}
ax2 = sns.scatterplot(data=df_pred, x="x0", y="x1", hue="y", palette="tab10")
# Compara los y de prueba vs. los y predichos para marcar los que no se clasificaron correctamente
for i in range(len(prediccion)):
    if prediccion[i] != y_test[i]:
        ax2.plot(df_pred["x0"].iloc[i], df_pred["x1"].iloc[i], "rx")
```